
VirtualGrasp: "Gleechi's software for hand interaction."

GameObject: In Unity, any node in the Hierarchy is called a GameObject.

Grasp: A hand grasps and holds an object

Gesture: A hand forms a gesture in air without contacting or interacting with object. Currently VG only support index finger push gesture. And it is only defined at a single frame as a "static" gesture. For example we are not supporting more "dynamic" gestures like waving yet.

GraspType: What types of grasps depicting shape of hand/fingers when holding an object, for example Pinch, Power grasp types.

GraspSynthesis: A process of creating hand grasping configuration – the wrist and fingers pose w.r.t the object – when an user triggers grasp with VR controllers.

FingerControlType: Describes how sensor is controlling the finger movement on the avatar hands. The different finger control types are explained in detail in [InteractionSetup](abc.html). 

GraspSynthesisMethod: Describes how a grasp is created when user triggers grasp to start interacting with an object. VG provides two alternative grasp synthesis methods - pre-baked static grasp (SG), and generate grasp dynamically on the fly, i.e. dynamic grasp (DG). See [Dynamic vs Static Grasping] to understand their differences and how to use them.

InteractionType: Describes how hand/object moves when VR user selected an object or triggers grasp to start interacting with an object. The different interaction types are explained in detail in [InteractionSetup]. 

ObjectJointType: Describes the movement relations between object and environment (world) or object and object. For example if joint type is "Floating", then object moving freely when grasped by a hand; however if it is of "Fixed" joint type, object is fixed to it's parent object/environment. See [Object and Articulation] for details of different types.

ObjectAffordance: Describes which kind of hand interaction we can have with this object in the virtual environment. For example if an object is "finger pushable", then you can push this object using index finger. See [Object and Articulation] for details of different affordances supported by VG. 

SensorOffset: When the virtual hands do not match to the position or rotation of your real hands holding the controllers, you can adjust an offset to synchronize them. See [InteractionSetup] to know how to adjust this offset.

SensorPose: An avatar hand's wrist 6-Dof pose determined by VR controller or a hand sensor like Leap Motion.  

VGSceneFiles: These are the scene files saved by VG library at end of each game run that stores all the sensor, control, avatar and object tree setup created by the game developers. 

StaticGrasp: Or SG, is a grasp synthesis method that creates grasping configuration from one of N grasps stored in a grasp database

DynamicGrasp: Or DG, is a grasp synthesis method that computes grasping configuration at the moment of grasp triggering

TriggerGrasp: Is a grasp interaction type where when user triggers grasp, avatar hand moves to the wrist pose in the synthesized grasp configuration around the object.

JumpGrasp: Is a grasp interaction type where when user triggers grasp, the object jumps to the grasped position in the avatar's hand. 

JumpPrimaryGrasp: Is a grasp interaction type where when user triggers grasp, the object jumps to the grasped position in the avatar's hand using the labeled primary grasp in the grasp DB. 

PreviewGrasp: Is a grasp interaction type where once user selected an object, the grasp configuration is previewed on the object, so that user can push the trigger button to pick up the object if the grasp is satisfactory.

PreviewOnly: Is a grasp interaction type where once user selected an object, the grasp configuration is previewed on the object, and the grasp trigger won't take effect to pick up object.

StickyHand: Is a fall-back grasp interaction type when object is not baked, where the grasp configuration is directly taken from the hand pose at the moment of grasp triggering as if hand is stick to the object.