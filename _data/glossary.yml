
VirtualGrasp: "Gleechi's software for hand interaction."

GameObject: In Unity, any node in the Hierarchy is called a GameObject.

InteractiveBehaviors: Referrs to when hand(s) interact with an object, how the object behaves (moves); it is determined by the object's Joint and Affordances setup. 

Grasp: A hand grasps and holds an object.

GraspConfiguration: Describes the hand pose when grasping an object; including wrist position, orientation and all finger bone's rotation angles.

Gesture: A hand forms a gesture in air without contacting or interacting with object. Currently VG only support index finger push gesture. And it is only defined at a single frame as a "static" gesture. For example we are not supporting more "dynamic" gestures like waving yet.

ObjectSelection: A runtime process of user selecting one of the many objects in the scene to interact with (interaction can be push or grasp); note only one object can be selected at a time.

GraspType: What types of grasps depicting shape of hand/fingers when holding an object, for example Pinch, Power grasp types.

GraspSynthesis: A runtime process of creating hand grasping configuration – the wrist and fingers pose w.r.t the object – when an user triggers grasp with VR controllers.

FingerControlType: Describes how sensor is controlling the finger movement on the avatar hands. The different finger control types are explained in detail in [InteractionSetup](abc.html). 

GraspSynthesisMethod: Describes how a grasp is created when user triggers grasp to start interacting with an object. See [Grasp Interaction](grasp_interaction.html) to understand different methods.

InteractionType: Describes how hand/object moves when VR user selected an object or triggers grasp to start interacting with an object. The different interaction types are explained in detail in [GraspInteraction]. 

ObjectJointType: Describes the movement relations between object and environment (world) or object and object. For example if joint type is "Floating", then object moving freely when grasped by a hand; however if it is of "Fixed" joint type, object is fixed to it's parent object/environment. See [Object and Articulation] for details of different types.

ObjectAffordance: Describes which kind of hand interaction we can have with this object in the virtual environment. For example if an object is "finger pushable", then you can push this object using index finger. See [Object and Articulation] for details of different affordances supported by VG. 

SensorOffset: When the virtual hands do not match to the position or rotation of your real hands holding the controllers, you can adjust an offset to synchronize them. See [InteractionSetup] to know how to adjust this offset.

SensorPose: An avatar hand's wrist 6-Dof pose determined by VR controller or a hand sensor like Leap Motion.  

VGSceneFiles: These are the scene files saved by VG library at end of each game run that stores all the sensor, control, avatar and object tree setup created by the game developers. 

StaticGrasp: Or SG, is a grasp synthesis method that creates grasping configuration from one of N grasps stored in a grasp database

DynamicGrasp: Or DG, is a grasp synthesis method that computes grasping configuration at the moment of grasp triggering

TriggerGrasp: Is a grasp interaction type where when user triggers grasp, avatar hand moves to the wrist pose in the synthesized grasp configuration around the object.

JumpGrasp: Is a grasp interaction type where when user triggers grasp, the object jumps to the grasped position in the avatar's hand. 

JumpPrimaryGrasp: Is a grasp interaction type where when user triggers grasp, the object jumps to the grasped position in the avatar's hand using the labeled primary grasp in the grasp DB. 

PreviewGrasp: Is a grasp interaction type where once user selected an object, the grasp configuration is previewed on the object, so that user can push the trigger button to pick up the object if the grasp is satisfactory.

PreviewOnly: Is a grasp interaction type where once user selected an object, the grasp configuration is previewed on the object, and the grasp trigger won't take effect to pick up object.

StickyHand: Is a fall-back grasp interaction type when object is not baked, where the grasp configuration is directly taken from the hand pose at the moment of grasp triggering as if hand is stick to the object.

PrimaryGrasp: Is a label of a grasp entry in grasp DB, and used only in StaticGrasp synthesis method, indicating this grasp is one of the few primarily used grasp on an object for a given hand.

GraspSpeed: A parameter in unit (second) specifying how long it takes for hand to move from SensorPose to synthesized grasp pose in TriggerGrasp interaction type, and how long it takes for object to jump to hand in JumpGrasp interaction type.

ReleaseSpeed: A parameter in unit (second) specifying how long it takes for hand to move back to SensorPose once a grasp is released. 

JointLimit: The parameter for object articulation of any joint types. For 1-dof joints (PRISMATIC and REVOLUTE) the limit is defined by a range of scalar values [Min, Max]. For 3-dof rotatioal joint (CONE) the limit is defined by a [swing, twist] angles. 

SwingAngle: For 3-dof Cone joint, this is an angle describes how much object swing away from the joint axis (at the center of the Cone-shaped joint limit boundary).

TwistAngle: For 3-dof Cone joint, this is an angle describes how much the object is rotating around its swinged away axis 

JointState: The status of a 1-dof joint (PRISMATIC or REVOLUTE), which can be represented by a single scalar value JointState in the range of JointLimit; JointState = 0 is the zero pose of the joint corresponding to the initial pose of the object.

DiscreteStates: The parameter for object articulation only relevant for 1-dof joints (PRISMATIC and REVOLUTE), and they are a set of N (N>=2) joint state values in the range of JointLimit; they are needed for State Affordances (BOUNCE, TWO_STAGE, SNAPS) which, when hand releases from the object, will pin the object into one of these discrete states. 

ScrewRate: A parameter for Revolute joint, describing how much the object linearly move along the axis given every degree of rotation, in unit (cm / degree); if > 0 will turn a Revolute joint into ScrewJoint.

JointCenter: The center point of an object's joint, around which an object is rotating around, specified by the Pivot transform’s position.

JointAxis: The axis of the joint, specified by the Pivot transform’s position; for Revolute joint the axis around which the object rotates; for Prismatic joint the axis along which the object translate; for Cone joint the axis in the center of the cone representing zero swing angle.

Pivot: The pivot transform needed to specify the JointCenter (position component of the transform and JointAxis (zaxis of the transform) of an object Joint.

PushPivot: A transform to specify along which direction (zaxis of the transform) the hand can approach and push an object that has push affordace; this direction is not the direction of object movement, but only used for object selection for push without physics situation.

ApproachDirection: The direction along which the PushAgent approaches the object to be pushed; PushPivot assigned to a pushable object is used to specify a preferred approach direction by the PushAgent. 

Affordance: An object affordance determines which kind of hand interaction can be done with the object, and how the object’s JointState reacts to the hand interaction.

InteractionAffordance: An object's interaction affordance determines what kind of action the hand can perform on the object, for example, graspable means the object can be grasped by a hand.

StateAffordance: An object's state affordance determines how the object's JointState reacts to the hand interaction.

PushAgent: Refers to who is performing the push action, for example if index finger tip is pushing, index finger tip is the push agent. 

Bounce: One of object's StateAffordance that is only relevant for 1-dof joints; when object is released from hand interaction, it bounces back to the lowest value of the DiscreteStates.

TwoStage: One of object's StateAffordance that is only relevant for 1-dof joints; when object is released from hand interaction, it bounces back to the highest and lowest values of the DiscreteStates in an alternating order.

Snaps: One of object's StateAffordance that is only relevant for 1-dof joints; when object is released from hand interaction, it snapes to the closest value of the DiscreteStates.

Joint: Joint is where two bones or GameObjects meet, and in VirtualGrasp it defines how a child object moves w.r.t. its parent (not the other way around); and different from the physics-based joint systems in some game engines like Unity, VG's joint system is non-physical (kinematic).

JointType: The type of a Joint, can be Floating, Fixed, Revolute, Prismatic and Cone. 

Floating: An unconstrained JointType, an object with this type of joint can be moved by hand freely.

Fixed: A completely constrained JointType, an object won't be moved relative to its parent object. 

Revolute: A constrained 1-dof rotational JointType, object rotates around an axis through a pivot point (JointCenter), limited by an angle range.

Prismatic: A constrained 1-dof translational JointType, object moves linearly along an axis, limited by an distance range. 

Cone: A constrained 3-dof rotational JointType, object rotates around a pivot point (JointCenter) limited by a cone limit, parameterized by a swing limit angle that determines the cone size, and twist limit angle that determines how much the object can rotate around the axis (center axis of the cone)

ScrewJoint: A joint of type Revolute when the parameter ScrewRate > 0, then the object will translate at an amount of ScrewRate (cm / degree) for every degree of rotation.

InteractionSequence: A interaction sequence is one segment of recorded sensor data that contains continuous frames for hand interaction with an object, or without any object. 

SensorRecordAndReplay: Refers to the functionality of VirtualGrasp to allow recording a set of InteractionSequences on SensorData during runtime interaction, and later replaying to reproduce those InteractionSequences.   

SensorData: Refers to the set signals provided by VR hand sensors (either VR controllers like Oculus Touch or Hand Tracking devices like LeapMotion); it contains the position and orientation of the wrist over time, as well as the grasp trigger.